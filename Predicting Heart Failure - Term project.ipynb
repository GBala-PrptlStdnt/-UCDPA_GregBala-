{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Heart failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this projects was published to Kaggle by ... in 2020? and contains hospital data from xxx patients admitted to the xxx Hospital in Pakistan between XXX and XXX with cardiac symptoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data as .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset imported from: https://www.kaggle.com/datasets/asgharalikhan/mortality-rate-heart-patient-pakistan-hospital\n",
    "\n",
    "HF_Dataset = 'HFDataset.csv'\n",
    "HFdata_df = pd.read_csv(HF_Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use .head() method on our dataframe to take an exploratory look at what data in holds. \n",
    "print(HFdata_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use .info() method to get information on the type of data in the dataframe\n",
    "print(HFdata_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the purposes of this analysis, \"Thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\", \"SK\", /\n",
    "#\"SK.React\", and \"Reaction\" columns will be dropped as no clear information was provided on what these data represent.\n",
    "\n",
    "drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values\n",
    "#Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign to variables functional data sets for later use\n",
    "\n",
    "Demographics = \n",
    "Enviro/Social =\n",
    "Bloods – Chem = \n",
    "Bloods – CBC =\n",
    "Sx o/A =\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of columns with unique string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HFdata_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0eb0082c27ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Use df[].unique() to determine all unique answers to “other”, “CO”, “Diagnosis”,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mUnique_other\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHFdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'HFdata_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Can I make this a for loop?\n",
    "\n",
    "\n",
    "#Use df[].unique() to determine all unique answers to “other”, “CO”, “Diagnosis”,\n",
    "Unique_other = HFdata_df[\"other\"].unique()\n",
    "Unique_CO = HFdata_df[\"CO\"].unique()\n",
    "Unique_Diagnosis = HFdata_df[\"Diagnosis\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Col_unique_list = [\"Others\", \"CO\", \"Diagnosis\",]\n",
    "\n",
    "for name in Col_unique_list:\n",
    "    unique_content = HFdata_df[name].unique()\n",
    "    print(unique_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use ReGex to filter for relevant keywords\n",
    "Relevant_keywords_CO = pd.list[chest pain, SOB,]\n",
    "Relevant_keywords_Diagnosis = \n",
    "Relevant_keywords_other = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HFdata_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-52b062b38a52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mAs_ser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHFdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CO\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mAs_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAs_ser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAs_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HFdata_df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "As_ser = HFdata_df[\"CO\"]\n",
    "As_str = As_ser.astype(str).str\n",
    "print(type(As_str))\n",
    "As_lowerc = As_str.lower()\n",
    "\n",
    "#for keyword in column\n",
    "# Create a new column called \"CO_chest_pain\" to store the search results\n",
    "\n",
    "#HFdata_df['CO_chest_pain'] = re.findall(r'\\b\\w*[^\\w\\s]\\w*\\s?chest\\s?pain\\w*[^\\w\\s]\\w*\\b', As_lowerc)\n",
    "\n",
    "HFdata_df['CO_chest_pain'] = As_lowerc.str.contains(r'\\w*\\s?chest\\s?pain\\w*', regex=True)\n",
    "\n",
    "print(HFdata_df['CO_chest_pain'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
